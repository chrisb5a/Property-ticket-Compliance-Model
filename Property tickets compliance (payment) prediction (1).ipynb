{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimization of AUC score for property violation tickets payment probability P_compl\n",
    "#We use the logistic regression and MLP classifier to train and predict\n",
    "#We optmize the AUC score above .75 with different parameter ex: Solve 'sag' and solver 'lbfgs'\n",
    "\n",
    "#The data (not included here) can be obtained from the detroit open data portal\n",
    "#links: \n",
    "#https://data.detroitmi.gov/property-parcels/building-permits/xw2a-a7tf\n",
    "#https://data.detroitmi.gov/property-parcels/trades-permits/635b-dsgv\n",
    "#https://data.detroitmi.gov/government/improve-detroit-submitted-issues/fwz3-w3yn\n",
    "#https://data.detroitmi.gov/public-safety/dpd-citizen-complaints-2016/kahe-efs3\n",
    "#https://data.detroitmi.gov/property-parcels/parcel-map/fxkw-udwf\n",
    "\n",
    "\n",
    "def Model1():\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.grid_search import GridSearchCV\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    df_test = pd.read_csv('test.csv')\n",
    "    df_train0 = pd.read_csv('train.csv', encoding='Latin-1')\n",
    "    df_address = pd.read_csv('addresses.csv')\n",
    "    df_location = pd.read_csv('latlons.csv')\n",
    "\n",
    "    train = df_train0[~np.isnan(df_train0['compliance'])]\n",
    "\n",
    "    df_address.set_index('address',inplace = True)\n",
    "    df_location.set_index('address',inplace = True)\n",
    "\n",
    "    df_address = df_address.join(df_location, how='left')\n",
    "\n",
    "    train.set_index('ticket_id', inplace = True)\n",
    "    df_address.set_index('ticket_id', inplace = True)\n",
    "\n",
    "    train_dat = train.join(df_address)\n",
    "\n",
    "    df_test.set_index('ticket_id', inplace = True)\n",
    "\n",
    "    test_dat = df_test.join(df_address)\n",
    "    train_dat = train_dat[~train['hearing_date'].isnull()]\n",
    "\n",
    "    drop_train_dat = ['payment_amount', 'payment_date', 'payment_status', 'balance_due', 'collection_status', 'compliance_detail']\n",
    "    drop_less_relevant = ['agency_name', 'inspector_name', 'violator_name', 'violation_street_number', \n",
    "                     'violation_street_name', 'violation_zip_code', 'mailing_address_str_number',\n",
    "                     'mailing_address_str_name', 'city', 'state', 'zip_code', \n",
    "                     'non_us_str_code', 'country','ticket_issued_date', 'hearing_date', 'violation_code', \n",
    "                     'violation_description', 'disposition', 'grafitti_status']\n",
    "\n",
    "    train_dat.drop(drop_train_dat, axis =1, inplace = True)\n",
    "    test_dat.drop(drop_less_relevant, axis =1, inplace = True)\n",
    "    train_dat.drop(drop_less_relevant, axis =1, inplace = True)\n",
    "\n",
    "    train_dat['lat'].fillna(method ='pad', inplace = True)\n",
    "    train_dat['lon'].fillna(method ='pad', inplace = True)\n",
    "    test_dat['lat'].fillna(method ='pad', inplace = True)\n",
    "    test_dat['lon'].fillna(method ='pad', inplace = True)\n",
    "\n",
    "    X_train = train_dat.drop('compliance', axis =1)\n",
    "    y_train =  train_dat['compliance']\n",
    "\n",
    "    X_test = test_dat\n",
    "\n",
    "\n",
    "    X_train_Scl = scaler.fit_transform(X_train)\n",
    "    X_test_Scl = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "    grid = { 'C': np.power(10.0, np.arange(-10, 10)), 'solver': ['sag'] }\n",
    "\n",
    "    lr = LogisticRegression(penalty='l2', max_iter=40, tol=10)\n",
    "\n",
    "    P_compl = lr.fit(X_train_Scl, y_train).predict_proba(X_test_Scl)[:,1]\n",
    "    GridROC = GridSearchCV(lr, grid, scoring='roc_auc')\n",
    "    GridROC.fit(X_train_Scl, y_train)\n",
    "    GridROC.best_score_\n",
    "    return P_compl\n",
    "\n",
    "Model1()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_train0 = pd.read_csv('train.csv', encoding='Latin-1')\n",
    "df_address = pd.read_csv('addresses.csv')\n",
    "df_location = pd.read_csv('latlons.csv')\n",
    "\n",
    "train = df_train0[~np.isnan(df_train0['compliance'])]\n",
    "\n",
    "df_address.set_index('address',inplace = True)\n",
    "df_location.set_index('address',inplace = True)\n",
    "\n",
    "df_address = df_address.join(df_location, how='left')\n",
    "\n",
    "train.set_index('ticket_id', inplace = True)\n",
    "df_address.set_index('ticket_id', inplace = True)\n",
    "\n",
    "train_dat = train.join(df_address)\n",
    "\n",
    "df_test.set_index('ticket_id', inplace = True)\n",
    "\n",
    "test_dat = df_test.join(df_address)\n",
    "train_dat = train_dat[~train['hearing_date'].isnull()]\n",
    "\n",
    "drop_train_dat = ['payment_amount', 'payment_date', 'payment_status', 'balance_due', 'collection_status', 'compliance_detail']\n",
    "drop_less_relevant = ['agency_name', 'inspector_name', 'violator_name', 'violation_street_number', \n",
    "                     'violation_street_name', 'violation_zip_code', 'mailing_address_str_number',\n",
    "                     'mailing_address_str_name', 'city', 'state', 'zip_code', \n",
    "                     'non_us_str_code', 'country','ticket_issued_date', 'hearing_date', 'violation_code', \n",
    "                     'violation_description', 'disposition', 'grafitti_status']\n",
    "\n",
    "train_dat.drop(drop_train_dat, axis =1, inplace = True)\n",
    "test_dat.drop(drop_less_relevant, axis =1, inplace = True)\n",
    "train_dat.drop(drop_less_relevant, axis =1, inplace = True)\n",
    "\n",
    "train_dat['lat'].fillna(method ='pad', inplace = True)\n",
    "train_dat['lon'].fillna(method ='pad', inplace = True)\n",
    "test_dat['lat'].fillna(method ='pad', inplace = True)\n",
    "test_dat['lon'].fillna(method ='pad', inplace = True)\n",
    "\n",
    "X_train = train_dat.drop('compliance', axis =1)\n",
    "y_train =  train_dat['compliance']\n",
    "\n",
    "X_test = test_dat\n",
    "\n",
    "\n",
    "X_train_Scl = scaler.fit_transform(X_train)\n",
    "X_test_Scl = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "MLP = MLPClassifier(hidden_layer_sizes = [10,10],alpha = 5, random_state = 0, \n",
    "                    solver = 'lbfgs')\n",
    "\n",
    "MLP.fit(X_train_Scl, y_train)\n",
    "P_compl = MLP.predict_proba(X_test_Scl)[:,1]\n",
    "\n",
    "grid_values = {'hidden_layer_sizes': [[100, 10], [150, 10]]}\n",
    "grid_AUC_scores = GridSearchCV(MLP, param_grid = grid_values, scoring = 'roc_auc')\n",
    "grid_AUC_scores.fit(X_train_Scl, y_train)\n",
    "\n",
    "print(grid_AUC_scores.best_score_)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
